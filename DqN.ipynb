{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use of reinforcement Learning along with Harmonic retracement models combined with technical indicators.\n",
    "\n",
    "Reward is based on whether the prices move along with the predicition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0             datetime      open      high       low     close  \\\n",
      "0           0  2019-09-08 17:30:00  10000.00  10000.00  10000.00  10000.00   \n",
      "1           1  2019-09-08 18:00:00  10000.00  10000.00  10000.00  10000.00   \n",
      "2           2  2019-09-08 18:30:00  10000.00  10000.00  10000.00  10000.00   \n",
      "3           3  2019-09-08 19:00:00  10344.77  10357.53  10342.90  10354.62   \n",
      "4           4  2019-09-08 19:30:00  10354.62  10357.35  10337.43  10340.12   \n",
      "\n",
      "    volume  \n",
      "0    0.002  \n",
      "1    0.000  \n",
      "2    0.000  \n",
      "3  136.177  \n",
      "4  335.482  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import argrelextrema\n",
    "import matplotlib.pyplot as plt\n",
    "from untrade.client import Client\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "data = pd.read_csv(\n",
    "    '/Users/tejasmacipad/Desktop/Final_inter_IIT_submission/BTC/BTC_2019_2023_30m.csv',\n",
    "    # parse_dates=['datetime'],  # Parse the 'datetime' column as datetime\n",
    "    # index_col='datetime'       # Use 'datetime' as the index\n",
    ")\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_extremes(price_values, i, order_dec):\n",
    "    max_idx = list(argrelextrema(price_values[:i], np.greater, order=order_dec)[0])\n",
    "    min_idx = list(argrelextrema(price_values[:i], np.less, order=order_dec)[0])\n",
    "    idx = max_idx + min_idx + [len(price_values[:i]) - 1]\n",
    "    idx.sort()\n",
    "    current_idx = idx[-5:]\n",
    "    current_pat = price_values[current_idx]\n",
    "    return current_idx, current_pat\n",
    "\n",
    "def identify_pattern(current_idx, current_pat, err_allowed, ab, bc, cd):\n",
    "    XA, AB, BC, CD = np.diff(current_pat)\n",
    "    \n",
    "    AB_range = np.array([ab[0] - err_allowed, ab[1] + err_allowed]) * abs(XA)\n",
    "    BC_range = np.array([bc[0] - err_allowed, bc[1] + err_allowed]) * abs(AB)\n",
    "    CD_range = np.array([cd[0] - err_allowed, cd[1] + err_allowed]) * abs(BC)\n",
    "\n",
    "    abs_AB, abs_BC, abs_CD = map(abs, (AB, BC, CD))\n",
    "\n",
    "    if XA > 0 and AB < 0 and BC > 0 and CD < 0:\n",
    "        if AB_range[0] < abs_AB < AB_range[1] and BC_range[0] < abs_BC < BC_range[1] and CD_range[0] < abs_CD < CD_range[1]:\n",
    "            return 1, current_idx\n",
    "    elif XA < 0 and AB > 0 and BC < 0 and CD > 0:\n",
    "        if AB_range[0] < abs_AB < AB_range[1] and BC_range[0] < abs_BC < BC_range[1] and CD_range[0] < abs_CD < CD_range[1]:\n",
    "            return -1, current_idx\n",
    "    return np.nan, []\n",
    "\n",
    "# Define all patterns\n",
    "harmonic_patterns = {\n",
    "    \"Butterfly\": ([0.786, 0.786], [0.382, 0.886], [1.618, 2.618]),\n",
    "    \"Gartley\": ([0.618, 0.618], [0.382, 0.886], [1.272, 1.618]),\n",
    "    \"Cypher\": ([0.382, 0.618], [1.272, 1.414], [0.786, 1.786]),\n",
    "    \"Bat\": ([0.382, 0.5], [0.382, 0.886], [1.618, 2.618]),\n",
    "    \"AltBat\": ([0.382, 0.382], [0.382, 0.886], [2.0, 3.618]),\n",
    "    \"Crab\": ([0.382, 0.618], [0.382, 0.886], [2.24, 3.618]),\n",
    "    \"DeepCrab\": ([0.886, 0.886], [0.382, 0.886], [2.618, 3.618]),\n",
    "    \"Shark\": ([0.382, 0.886], [1.13, 1.618], [1.618, 2.24]),\n",
    "    \"WhiteSwan\": ([1.382, 2.618], [0.236, 0.5], [1.128, 2.0]),\n",
    "    \"BlackSwan\": ([0.382, 0.724], [2.0, 4.237], [0.5, 0.886])\n",
    "}\n",
    "\n",
    "def detect_harmonic_pattern(price, order_dec=5, err_allowed=0.1):\n",
    "    signals = {pattern: [] for pattern in harmonic_patterns}\n",
    "    patterns = {pattern: [] for pattern in harmonic_patterns}\n",
    "    \n",
    "    for i in range(100, len(price)):\n",
    "        current_idx, current_pat = extract_extremes(price.values, i, order_dec)\n",
    "\n",
    "        for pattern_name, ratios in harmonic_patterns.items():\n",
    "            pattern_signal, pattern_idx = identify_pattern(current_idx, current_pat, err_allowed, *ratios)\n",
    "            signals[pattern_name].append(pattern_signal)\n",
    "            if not np.isnan(pattern_signal):\n",
    "                patterns[pattern_name].append((pattern_signal, pattern_idx))\n",
    "    \n",
    "    return signals, patterns\n",
    "\n",
    "def plot_harmonic_patterns(df, patterns):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Candlestick(x=df.index, \n",
    "                                 open=df['open'], \n",
    "                                 high=df['high'], \n",
    "                                 low=df['low'], \n",
    "                                 close=df['close'], \n",
    "                                 name='Candlesticks'))\n",
    "    \n",
    "    colors = {\n",
    "        \"Butterfly\": \"blue\", \"Bat\": \"green\", \"AltBat\": \"purple\",\n",
    "        \"Crab\": \"red\", \"DeepCrab\": \"pink\", \"Cypher\": \"orange\",\n",
    "        \"Gartley\": \"cyan\", \"Shark\": \"yellow\", \"WhiteSwan\": \"black\", \"BlackSwan\": \"brown\"\n",
    "    }\n",
    "    \n",
    "    for pattern_name, pattern_list in patterns.items():\n",
    "        for signal, indices in pattern_list:\n",
    "            x_vals = df.index[indices]\n",
    "            y_vals = df.close.iloc[indices]\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=x_vals, y=y_vals, mode='lines+markers',\n",
    "                line=dict(color=colors[pattern_name], width=2),\n",
    "                marker=dict(size=8, color=colors[pattern_name]),\n",
    "                name=f\"{pattern_name} {'Bullish' if signal == 1 else 'Bearish'}\"\n",
    "            ))\n",
    "\n",
    "    fig.update_layout(title='Harmonic Patterns',\n",
    "                      xaxis_title='Date',\n",
    "                      yaxis_title='Price',\n",
    "                      xaxis_rangeslider_visible=False)\n",
    "    fig.show()\n",
    "\n",
    "# Example Usage\n",
    "# Assuming df is a Pandas DataFrame with 'close' prices and OHLC data\n",
    "signals, patterns = detect_harmonic_pattern(data['close'])\n",
    "# plot_harmonic_patterns(data, patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat, sig = signals, patterns\n",
    "signals, patterns = pat, sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym import spaces\n",
    "import random\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from scipy.signal import argrelextrema\n",
    "from untrade.client import Client\n",
    "\n",
    "# Harmonic Pattern Detection Functions\n",
    "def extract_extremes(price_values, i, order_dec):\n",
    "    max_idx = list(argrelextrema(price_values[:i], np.greater, order=order_dec)[0])\n",
    "    min_idx = list(argrelextrema(price_values[:i], np.less, order=order_dec)[0])\n",
    "    idx = max_idx + min_idx + [len(price_values[:i]) - 1]\n",
    "    idx.sort()\n",
    "    current_idx = idx[-5:]\n",
    "    current_pat = price_values[current_idx]\n",
    "    return current_idx, current_pat\n",
    "\n",
    "def identify_pattern(current_idx, current_pat, err_allowed, ab, bc, cd):\n",
    "    XA, AB, BC, CD = np.diff(current_pat)\n",
    "    \n",
    "    AB_range = np.array([ab[0] - err_allowed, ab[1] + err_allowed]) * abs(XA)\n",
    "    BC_range = np.array([bc[0] - err_allowed, bc[1] + err_allowed]) * abs(AB)\n",
    "    CD_range = np.array([cd[0] - err_allowed, cd[1] + err_allowed]) * abs(BC)\n",
    "\n",
    "    abs_AB, abs_BC, abs_CD = map(abs, (AB, BC, CD))\n",
    "\n",
    "    if XA > 0 and AB < 0 and BC > 0 and CD < 0:\n",
    "        if AB_range[0] < abs_AB < AB_range[1] and BC_range[0] < abs_BC < BC_range[1] and CD_range[0] < abs_CD < CD_range[1]:\n",
    "            return 1, current_idx\n",
    "    elif XA < 0 and AB > 0 and BC < 0 and CD > 0:\n",
    "        if AB_range[0] < abs_AB < AB_range[1] and BC_range[0] < abs_BC < BC_range[1] and CD_range[0] < abs_CD < CD_range[1]:\n",
    "            return -1, current_idx\n",
    "    return np.nan, []\n",
    "\n",
    "harmonic_patterns = {\n",
    "    \"Butterfly\": ([0.786, 0.786], [0.382, 0.886], [1.618, 2.618]),\n",
    "    \"Gartley\": ([0.618, 0.618], [0.382, 0.886], [1.272, 1.618]),\n",
    "    \"Cypher\": ([0.382, 0.618], [1.272, 1.414], [0.786, 1.786]),\n",
    "    \"Bat\": ([0.382, 0.5], [0.382, 0.886], [1.618, 2.618]),\n",
    "    \"AltBat\": ([0.382, 0.382], [0.382, 0.886], [2.0, 3.618]),\n",
    "    \"Crab\": ([0.382, 0.618], [0.382, 0.886], [2.24, 3.618]),\n",
    "    \"DeepCrab\": ([0.886, 0.886], [0.382, 0.886], [2.618, 3.618]),\n",
    "    \"Shark\": ([0.382, 0.886], [1.13, 1.618], [1.618, 2.24]),\n",
    "    \"WhiteSwan\": ([1.382, 2.618], [0.236, 0.5], [1.128, 2.0]),\n",
    "    \"BlackSwan\": ([0.382, 0.724], [2.0, 4.237], [0.5, 0.886])\n",
    "}\n",
    "\n",
    "def detect_harmonic_pattern(price, order_dec=5, err_allowed=0.1):\n",
    "    signals = {pattern: [] for pattern in harmonic_patterns}\n",
    "    patterns = {pattern: [] for pattern in harmonic_patterns}\n",
    "    \n",
    "    for i in range(100, len(price)):  # 100-period offset\n",
    "        current_idx, current_pat = extract_extremes(price.values, i, order_dec)\n",
    "\n",
    "        for pattern_name, ratios in harmonic_patterns.items():\n",
    "            pattern_signal, pattern_idx = identify_pattern(current_idx, current_pat, err_allowed, *ratios)\n",
    "            signals[pattern_name].append(pattern_signal)\n",
    "            if not np.isnan(pattern_signal):\n",
    "                patterns[pattern_name].append((pattern_signal, pattern_idx))\n",
    "    \n",
    "    return signals, patterns\n",
    "\n",
    "signals, patterns = detect_harmonic_pattern(data['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/55/_kpfspls6xq0pzzm_dl4ylxc0000gn/T/ipykernel_93207/126654874.py:52: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  self.df = self.df.fillna(method='ffill').reset_index(drop=True)\n",
      "/var/folders/55/_kpfspls6xq0pzzm_dl4ylxc0000gn/T/ipykernel_93207/126654874.py:106: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = GradScaler()\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/var/folders/55/_kpfspls6xq0pzzm_dl4ylxc0000gn/T/ipykernel_93207/126654874.py:133: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  dones = torch.FloatTensor(dones).to(self.device)\n",
      "/var/folders/55/_kpfspls6xq0pzzm_dl4ylxc0000gn/T/ipykernel_93207/126654874.py:134: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/10 | Total Return: -0.12\n",
      "Episode 2/10 | Total Return: 0.27\n",
      "Episode 3/10 | Total Return: 0.06\n",
      "Episode 4/10 | Total Return: 0.28\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 242\u001b[0m\n\u001b[1;32m    240\u001b[0m total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(agent\u001b[38;5;241m.\u001b[39mmemory) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size:\n\u001b[0;32m--> 242\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 140\u001b[0m, in \u001b[0;36mTurboDQNAgent.replay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    138\u001b[0m     loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSmoothL1Loss()(current_q\u001b[38;5;241m.\u001b[39msqueeze(), target_q)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# TECHNICAL INDICATOR HELPERS#\n",
    "##############################\n",
    "def calculate_rsi(series, period=14):\n",
    "    delta = series.diff()\n",
    "    gain = delta.copy()\n",
    "    loss = delta.copy()\n",
    "    gain[gain < 0] = 0\n",
    "    loss[loss > 0] = 0\n",
    "    avg_gain = gain.rolling(window=period).mean()\n",
    "    avg_loss = loss.abs().rolling(window=period).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def calculate_atr(df, period=14):\n",
    "    df['TR'] = pd.DataFrame({\n",
    "        'hl': df['high'] - df['low'],\n",
    "        'hc': abs(df['high'] - df['close'].shift(1)),\n",
    "        'lc': abs(df['low'] - df['close'].shift(1))\n",
    "    }).max(axis=1)\n",
    "    return df['TR'].rolling(window=period).mean()\n",
    "\n",
    "##############################\n",
    "# TRADING ENVIRONMENT        #\n",
    "##############################\n",
    "class EnhancedTradingEnv(gym.Env):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        if len(df) < 100:\n",
    "            raise ValueError(\"Input data must have at least 100 rows for the 100-row offset.\")\n",
    "        self.df = df.copy()\n",
    "        self.current_step = 0\n",
    "        self.cash = 100000\n",
    "        self.position = 0\n",
    "        self.entry_price = 0\n",
    "\n",
    "        # Add harmonic pattern columns â€“ each pattern gets its own column.\n",
    "        global signals, patterns\n",
    "        signals, _ = signals, patterns\n",
    "        for pattern in harmonic_patterns:\n",
    "            arr = np.full(len(self.df), np.nan)\n",
    "            valid = np.array(signals[pattern])\n",
    "            # Preserve the 100-row offset.\n",
    "            if len(valid) > 0 and len(arr) >= 100 + len(valid):\n",
    "                arr[100:100+len(valid)] = valid\n",
    "            self.df[f'pattern_{pattern}'] = arr\n",
    "\n",
    "        # Add technical indicators: RSI and ATR.\n",
    "        self.df['RSI'] = calculate_rsi(self.df['close'])\n",
    "        self.df['ATR'] = calculate_atr(self.df)\n",
    "        # Instead of dropping rows (which can lead to an empty DataFrame), fill forward.\n",
    "        self.df = self.df.fillna(method='ffill').reset_index(drop=True)\n",
    "\n",
    "        # Use only numeric columns for observations.\n",
    "        self.numeric_features = self.df.select_dtypes(include=[np.number]).columns\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(len(self.numeric_features),), dtype=np.float32\n",
    "        )\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.cash = 100000\n",
    "        self.position = 0\n",
    "        self.entry_price = 0\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        if self.current_step >= len(self.df):\n",
    "            self.current_step = len(self.df) - 1\n",
    "        return self.df[self.numeric_features].iloc[self.current_step].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        current_price = self.df.iloc[self.current_step]['close']\n",
    "        reward = 0\n",
    "        done = self.current_step >= len(self.df) - 1\n",
    "        if action == 1 and self.position == 0:  # Buy\n",
    "            self.position = 1\n",
    "            self.entry_price = current_price * 1.0002  # include transaction cost\n",
    "        elif action == 2 and self.position == 1:  # Sell\n",
    "            pnl = (current_price * 0.9998 - self.entry_price)\n",
    "            reward = np.log1p(pnl / self.cash)\n",
    "            self.cash += pnl\n",
    "            self.position = 0\n",
    "        self.current_step += 1\n",
    "        done = done or (self.cash < 10000)\n",
    "        return self._next_observation(), reward, done, {}\n",
    "\n",
    "##############################\n",
    "# DQN AGENT WITH BATCHNORM   #\n",
    "##############################\n",
    "class TurboDQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\")\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(state_size, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, action_size)\n",
    "        ).to(self.device)\n",
    "        self.optimizer = optim.AdamW(self.model.parameters(), lr=0.0001)\n",
    "        self.scaler = GradScaler()\n",
    "        self.memory = []\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.97\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(3)\n",
    "        # Switch temporarily to eval mode to avoid batchnorm errors on batch-size=1.\n",
    "        self.model.eval()\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.model(state_tensor)\n",
    "        self.model.train()\n",
    "        return q_values.argmax().item()\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        batch = random.sample(self.memory, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        states = torch.FloatTensor(np.array(states)).to(self.device)\n",
    "        actions = torch.LongTensor(actions).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).to(self.device)\n",
    "        next_states = torch.FloatTensor(np.array(next_states)).to(self.device)\n",
    "        dones = torch.FloatTensor(dones).to(self.device)\n",
    "        with autocast():\n",
    "            current_q = self.model(states).gather(1, actions.unsqueeze(1))\n",
    "            next_q = self.model(next_states).max(1)[0].detach()\n",
    "            target_q = rewards + (1 - dones) * self.gamma * next_q\n",
    "            loss = nn.SmoothL1Loss()(current_q.squeeze(), target_q)\n",
    "        self.optimizer.zero_grad()\n",
    "        self.scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "        self.scaler.step(self.optimizer)\n",
    "        self.scaler.update()\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "##############################\n",
    "# PROCESS DATA FUNCTION      #\n",
    "##############################\n",
    "def process_data(df, agent):\n",
    "    df = df.copy()\n",
    "    df['Signal'] = 0\n",
    "    df['trade'] = 0\n",
    "    df['SL'] = np.nan\n",
    "    df['TP'] = np.nan\n",
    "    df['trade_type'] = \"square-off\"\n",
    "    # Recompute harmonic patterns (with offset preserved)\n",
    "    global signals, patterns\n",
    "    signals, _ = signals, patterns\n",
    "    for pattern in harmonic_patterns:\n",
    "        arr = np.full(len(df), np.nan)\n",
    "        valid = np.array(signals[pattern])\n",
    "        if len(valid) > 0 and len(arr) >= 100 + len(valid):\n",
    "            arr[100:100+len(valid)] = valid\n",
    "        df[f'pattern_{pattern}'] = arr\n",
    "    df['ATR'] = calculate_atr(df)\n",
    "    df['RSI'] = calculate_rsi(df['close'])\n",
    "    # Build an environment from this processed DataFrame.\n",
    "    env = EnhancedTradingEnv(df)\n",
    "    state = env.reset()\n",
    "    # Use the agent to simulate through the environment; update trade signals based on each step.\n",
    "    while True:\n",
    "        action = agent.act(state)\n",
    "        idx = env.current_step  # index in env.df (post fillna)\n",
    "        if idx < len(env.df):\n",
    "            if action == 1:\n",
    "                df.loc[df.index[idx], 'Signal'] = 1\n",
    "                df.loc[df.index[idx], 'trade'] = 1\n",
    "                df.loc[df.index[idx], 'trade_type'] = \"long\"\n",
    "                df.loc[df.index[idx], 'SL'] = df['close'].iloc[idx] - 1.5 * df['ATR'].iloc[idx]\n",
    "                df.loc[df.index[idx], 'TP'] = df['close'].iloc[idx] + 3 * df['ATR'].iloc[idx]\n",
    "            elif action == 2:\n",
    "                df.loc[df.index[idx], 'Signal'] = -1\n",
    "                df.loc[df.index[idx], 'trade'] = -1\n",
    "                df.loc[df.index[idx], 'trade_type'] = \"short\"\n",
    "                df.loc[df.index[idx], 'SL'] = df['close'].iloc[idx] + 1.5 * df['ATR'].iloc[idx]\n",
    "                df.loc[df.index[idx], 'TP'] = df['close'].iloc[idx] - 3 * df['ATR'].iloc[idx]\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            break\n",
    "        state = next_state\n",
    "    return df\n",
    "\n",
    "##############################\n",
    "# POST-PROCESS & BACKTEST    #\n",
    "##############################\n",
    "def strat(data):\n",
    "    signal = []\n",
    "    prev = None\n",
    "    for value in data[\"Signal\"]:\n",
    "        if value == prev:\n",
    "            signal.append(0)\n",
    "        else:\n",
    "            signal.append(value)\n",
    "        prev = value\n",
    "    data[\"signals\"] = signal\n",
    "    data = data[['datetime', 'open', 'high', 'low', 'close', 'volume', 'signals', 'trade_type']]\n",
    "    return data\n",
    "\n",
    "def perform_backtest(csv_file_path):\n",
    "    client = Client()\n",
    "    result = client.backtest(\n",
    "        jupyter_id=\"vraj2811\",  # your Jupyter ID\n",
    "        file_path=csv_file_path,\n",
    "        leverage=1,  # Adjust leverage if needed\n",
    "    )\n",
    "    return result\n",
    "\n",
    "##############################\n",
    "# MAIN EXECUTION             #\n",
    "##############################\n",
    "if __name__ == \"__main__\":\n",
    "    data = pd.read_csv(\"/Users/tejasmacipad/Desktop/Final_inter_IIT_submission/BTC/BTC_2019_2023_30m.csv\", parse_dates=['datetime'])\n",
    "    # Precompute ATR for consistency (OPTIONAL)\n",
    "    data['ATR'] = calculate_atr(data)\n",
    "    \n",
    "    # Initialize environment and agent (note: environment processing uses a 100-row offset)\n",
    "    env = EnhancedTradingEnv(data)\n",
    "    agent = TurboDQNAgent(env.observation_space.shape[0], env.action_space.n)\n",
    "    \n",
    "    episodes = 10\n",
    "    batch_size = 512\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        while True:\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.memory.append((state, action, reward, next_state, done))\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            if len(agent.memory) >= batch_size:\n",
    "                agent.replay(batch_size)\n",
    "            if done:\n",
    "                break\n",
    "        print(f\"Episode {episode+1}/{episodes} | Total Return: {total_reward:.2f}\")\n",
    "    \n",
    "    processed_df = process_data(data, agent)\n",
    "    filtered_df = strat(processed_df)\n",
    "    filtered_df.to_csv(\"trading_signals.csv\", index=False)\n",
    "    backtest_results = perform_backtest(\"trading_signals.csv\")\n",
    "    for result in backtest_results:\n",
    "        print(f\"{result['metric']}: {result['value']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = strat(processed_data)\n",
    "filtered_data.to_csv(\"final_signals.csv\", index=False)\n",
    "\n",
    "# Backtest\n",
    "backtest_results = perform_backtest(\"final_signals.csv\")\n",
    "for result in backtest_results:\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
